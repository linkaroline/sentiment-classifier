{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "POSH Sentiment Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGt3QhK-RH58",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815
        },
        "outputId": "5512e7b1-8390-4afa-e34e-f7d72bbc0ac6"
      },
      "source": [
        "pip install -U sentence-transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/78/e0/65ad8fd86eba720412d9ff102c4a3540a113bbc6cd29b01e7ecc33ebb1fa/sentence-transformers-0.3.2.tar.gz (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 4.9MB/s \n",
            "\u001b[?25hCollecting transformers>=3.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 16.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.6.0+cu101)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->sentence-transformers) (0.7)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->sentence-transformers) (2.23.0)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 14.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->sentence-transformers) (20.4)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->sentence-transformers) (3.0.12)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 52.7MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 50.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.2.0->sentence-transformers) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence-transformers) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=3.0.2->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=3.0.2->sentence-transformers) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=3.0.2->sentence-transformers) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=3.0.2->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers>=3.0.2->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=3.0.2->sentence-transformers) (7.1.2)\n",
            "Building wheels for collected packages: sentence-transformers, sacremoses\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-0.3.2-cp36-none-any.whl size=93964 sha256=f5804cb66c292eb160e7f744d77c66f300e1648175c7fed40d758da6c5e2b995\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/06/a0/567f3651876165429f6510d3197b011652a25e547552816824\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=98d37d09a043786e45cda0065c36b7f13bcbb06216121fd471a4687c275fe6a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sentence-transformers sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers, sentence-transformers\n",
            "Successfully installed sacremoses-0.0.43 sentence-transformers-0.3.2 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deaExQN129T8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import classification_report\n",
        "from pprint import pprint\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from typing import List\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxhyDusFT9WI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import dataset\n",
        "df = pd.read_csv(\"labelled_sentiments.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nhIkruzXabW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Split dataset into training and testing data\n",
        "train, test = train_test_split(df, \n",
        "                               test_size = .2, \n",
        "                               stratify=df[\"label\"], \n",
        "                               random_state=1988)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNbwzDp5WqNg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b1c20719-fc7e-42b1-99ee-8851bebfa4b8"
      },
      "source": [
        "#Encode X_train Inputs\n",
        "sentencemodel = SentenceTransformer('roberta-base-nli-mean-tokens')\n",
        "\n",
        "X_train = sentencemodel.encode(train[\"text\"].tolist())\n",
        "y_train = train[\"label\"]\n",
        "print(\"finished encoding X_train inputs\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 459M/459M [00:09<00:00, 48.7MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "finished encoding X_train inputs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ieKWQwPXnpg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "83304b0c-dc12-497a-b641-81ec2f1efe97"
      },
      "source": [
        "# Train Classifier\n",
        "rfclf = RandomForestClassifier(verbose=True, n_jobs=-1)\n",
        "rfclf.fit(X_train, y_train)\n",
        "print(f\"training accuracy: {rfclf.score(X_train, y_train)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   58.5s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.1min finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.6s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "training accuracy: 0.9937175777482339\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    1.3s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1EmaCf0WzK7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "0b92ba3c-69c5-4723-eb6e-972d5c6ac293"
      },
      "source": [
        "#Evaluate against Test Data\n",
        "X_test = sentencemodel.encode(test[\"text\"].tolist())\n",
        "y_test = test[\"label\"]\n",
        "print(f\"Test accuracy: {rfclf.score(X_test, y_test)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.9607965801272026\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.3s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HooMUK1DX3Vd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "outputId": "77ef16dc-6a16-44dd-d23d-a7710f6ba881"
      },
      "source": [
        "#Results\n",
        "preds = rfclf.predict(X_test)\n",
        "print(classification_report(y_test, preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.90      0.84      0.87       733\n",
            "           0       0.96      0.98      0.97      6677\n",
            "           1       0.98      0.93      0.96      2181\n",
            "\n",
            "    accuracy                           0.96      9591\n",
            "   macro avg       0.95      0.92      0.93      9591\n",
            "weighted avg       0.96      0.96      0.96      9591\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.3s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQyClD0kvCNT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "ee3cd557-c188-4b39-d207-c90c518e8ba5"
      },
      "source": [
        "#Review current parameters\n",
        "print('Parameters currently in use:\\n')\n",
        "pprint(rfclf.get_params())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameters currently in use:\n",
            "\n",
            "{'bootstrap': True,\n",
            " 'ccp_alpha': 0.0,\n",
            " 'class_weight': None,\n",
            " 'criterion': 'gini',\n",
            " 'max_depth': None,\n",
            " 'max_features': 'auto',\n",
            " 'max_leaf_nodes': None,\n",
            " 'max_samples': None,\n",
            " 'min_impurity_decrease': 0.0,\n",
            " 'min_impurity_split': None,\n",
            " 'min_samples_leaf': 1,\n",
            " 'min_samples_split': 2,\n",
            " 'min_weight_fraction_leaf': 0.0,\n",
            " 'n_estimators': 100,\n",
            " 'n_jobs': -1,\n",
            " 'oob_score': False,\n",
            " 'random_state': None,\n",
            " 'verbose': True,\n",
            " 'warm_start': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zWRPaTXIkS6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "outputId": "94a587ae-a1f9-4f03-b777-b17d6bc23ed4"
      },
      "source": [
        "#Grid Search\n",
        "parameters = {'criterion':['gini','entropy'],\n",
        "              'min_samples_leaf':[1,2]}\n",
        "grid = GridSearchCV(rfclf, parameters, cv=3, n_jobs=-1, verbose=True)\n",
        "\n",
        "grid.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed: 16.8min finished\n",
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  1.0min\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score=nan,\n",
              "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                              class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              max_samples=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              n_estimators=100, n_jobs=-1,\n",
              "                                              oob_score=False,\n",
              "                                              random_state=None, verbose=True,\n",
              "                                              warm_start=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'criterion': ['gini', 'entropy'],\n",
              "                         'min_samples_leaf': [1, 2]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ci1_PsCPkGXA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "81e98803-76d2-49f1-b237-ee5a130d9118"
      },
      "source": [
        "#Best Parameters\n",
        "grid.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 'entropy', 'min_samples_leaf': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kp0W7iki0mpH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "f363afef-da00-4fc2-e53a-7f0e5822c175"
      },
      "source": [
        "#Gridsearch Results\n",
        "pd.DataFrame(grid.cv_results_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_criterion</th>\n",
              "      <th>param_min_samples_leaf</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>164.223350</td>\n",
              "      <td>3.102275</td>\n",
              "      <td>0.871905</td>\n",
              "      <td>0.094949</td>\n",
              "      <td>gini</td>\n",
              "      <td>1</td>\n",
              "      <td>{'criterion': 'gini', 'min_samples_leaf': 1}</td>\n",
              "      <td>0.921717</td>\n",
              "      <td>0.913819</td>\n",
              "      <td>0.913037</td>\n",
              "      <td>0.916191</td>\n",
              "      <td>0.003921</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>147.503776</td>\n",
              "      <td>1.328198</td>\n",
              "      <td>0.792550</td>\n",
              "      <td>0.080288</td>\n",
              "      <td>gini</td>\n",
              "      <td>2</td>\n",
              "      <td>{'criterion': 'gini', 'min_samples_leaf': 2}</td>\n",
              "      <td>0.917729</td>\n",
              "      <td>0.909830</td>\n",
              "      <td>0.912255</td>\n",
              "      <td>0.913271</td>\n",
              "      <td>0.003304</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>174.177743</td>\n",
              "      <td>1.842895</td>\n",
              "      <td>0.698964</td>\n",
              "      <td>0.004772</td>\n",
              "      <td>entropy</td>\n",
              "      <td>1</td>\n",
              "      <td>{'criterion': 'entropy', 'min_samples_leaf': 1}</td>\n",
              "      <td>0.920231</td>\n",
              "      <td>0.913897</td>\n",
              "      <td>0.914444</td>\n",
              "      <td>0.916191</td>\n",
              "      <td>0.002866</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>168.834847</td>\n",
              "      <td>2.157618</td>\n",
              "      <td>0.582345</td>\n",
              "      <td>0.203240</td>\n",
              "      <td>entropy</td>\n",
              "      <td>2</td>\n",
              "      <td>{'criterion': 'entropy', 'min_samples_leaf': 2}</td>\n",
              "      <td>0.920701</td>\n",
              "      <td>0.913584</td>\n",
              "      <td>0.914757</td>\n",
              "      <td>0.916347</td>\n",
              "      <td>0.003115</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
              "0     164.223350      3.102275  ...        0.003921                2\n",
              "1     147.503776      1.328198  ...        0.003304                4\n",
              "2     174.177743      1.842895  ...        0.002866                2\n",
              "3     168.834847      2.157618  ...        0.003115                1\n",
              "\n",
              "[4 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65_e0TShwN-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bestmodel=grid.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufV_frjXXvXg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "outputId": "af56bae5-9311-4fed-b291-115217c76762"
      },
      "source": [
        "#Results with Gridsearch\n",
        "preds = bestmodel.predict(X_test)\n",
        "print(classification_report(y_test, preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.89      0.84      0.86       733\n",
            "           0       0.96      0.98      0.97      6677\n",
            "           1       0.98      0.93      0.95      2181\n",
            "\n",
            "    accuracy                           0.96      9591\n",
            "   macro avg       0.94      0.92      0.93      9591\n",
            "weighted avg       0.96      0.96      0.96      9591\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AouMNixJNTV7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "11949723-9f8e-44d3-e192-17c2efb25f17"
      },
      "source": [
        "#Add model predictions to test data file to view results\n",
        "test['modelresults']=preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lqZon0vN39y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.to_csv(\"modelresults.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCikKi4mXyis",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save model\n",
        "pickle.dump(rfclf, open(\"sentiment_model.pkl\", \"wb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2u5ZxmaTrAzC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Productionizing the Model: Define X_train and y_train\n",
        "X_train= train[\"text\"].tolist()\n",
        "y_train=train[\"label\"].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTzfKTWS8qIM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Productionizing the Model: Create class \n",
        "class SentimentClassifier:\n",
        "  def __init__(self, model_path: str = None,\n",
        "               train_mode = True):\n",
        "    self.model = None\n",
        "    if model_path:\n",
        "      self.load(model_path)\n",
        "    self.train_mode = train_mode\n",
        "\n",
        "  def load(self, model_path: str) -> bool:\n",
        "    print(\"loading :\", model_path)\n",
        "    loaded_model = pickle.load(open(model_path, \"rb\"))\n",
        "    self.model = loaded_model[\"model\"]\n",
        "    self.train_mode = False\n",
        "    return True\n",
        "\n",
        "  def save(self, model_path: str, model_name: str) -> str:\n",
        "    model_properties = {\"model\": self.model}\n",
        "    filename = model_path+model_name+\".pkl\"\n",
        "    pickle.dump(model_properties, open(filename,\"wb\"))\n",
        "    return filename\n",
        "  \n",
        "  def train(self, X: List[str], y: List[int] ) -> float:\n",
        "    \"\"\"\" Take in X,y. Fit model to data and return\n",
        "         the model's train accuracy \"\"\"\n",
        "    # 1. Clean X and convert features\n",
        "    self.encoder = SentenceTransformer('roberta-base-nli-mean-tokens')\n",
        "    X_train = self.encoder.encode(X)\n",
        "\n",
        "    # 2. Load and fit model to X,y \n",
        "    self.model  = RandomForestClassifier(verbose=True, n_jobs=-1, criterion= 'entropy', min_samples_leaf=1)\n",
        "    self.model.fit(X_train, y)\n",
        "\n",
        "    # 3. Calcuate train accuracy\n",
        "    train_acc = self.model.score(X_train, y)\n",
        "    return train_acc\n",
        "  \n",
        "  def predict(self, inputs: List[str]) -> List[str]:\n",
        "    \"\"\" Take in a list of string inputs and output\n",
        "        a list of the model's predictions \"\"\"\n",
        "\n",
        "    # 1. Convert inputs into features\n",
        "    input_feats = self.encoder.encode(inputs)\n",
        "\n",
        "    # 2. Run model on features and get predictions\n",
        "    preds = self.model.predict(input_feats)\n",
        "    return preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGRCWIUOaYUa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "23292723-88a0-4719-9242-0c7ae42d6770"
      },
      "source": [
        "model = SentimentClassifier()\n",
        "model.train(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   57.6s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.1min finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.4s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.9s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9943171450170747"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwvivnzcB5Wd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"./\", \"saved_model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NLXSXc0nw7-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_model = SentimentModel(\"saved_model.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}